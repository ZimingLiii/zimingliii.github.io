---
title: "Environment and Interaction Aware Gen-AI Avatars in Virtual Reality"
excerpt: "LLM, VR, interaction"
header:
    teaser: '/teasers/2025-ieee-vr-llm-spatial-interactions.png'
collection: projects
---

This project explores how Large Language Model (LLM) agents can bring more intelligence and realism to humanâ€“AI interactions in Virtual Reality. Instead of limiting AI avatars to simple voice-based responses, the system enables them to understand their surroundings and react dynamically to environmental and interaction cues within VR. By defining a structured text-based schema that represents virtual spaces and interactive elements, the project allows AI avatars to generate contextually relevant behaviors and dialogue that reflect what they perceive in their virtual environments.

## Video

<iframe width="560" height="315" src="https://www.youtube.com/embed/lxX38PiXScM?si=N_3MVjuOKQ83xZ5W" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## Related Publication:

- <a href="https://ieeexplore.ieee.org/document/10937341" target="_blank" rel="noopener noreferrer">Z. Li, H. Zhang, C. Peng and R. Peiris, "Exploring Large Language Model-Driven Agents for Environment-Aware Spatial Interactions and Conversations in Virtual Reality Role-Play Scenarios," 2025 IEEE Conference Virtual Reality and 3D User Interfaces (VR), Saint Malo, France, 2025, pp. 1-11, doi: 10.1109/VR59515.2025.00025.</a>
